{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```{admonition} Lernziele\n",
    ":class: keypoints\n",
    "- Lernende befassen sich mit der maschinellen Abfrage von DAten in Open Data Portalen unter Anwendung von SPARQL\n",
    "- Lernende praktizieren verschiedene SPARQL Techniken über die API von data.europa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorwort**\n",
    "\n",
    "Das Ziel ist, eine realistische Verwendung der Abfragesprache SPARQL zu demonstieren. Anhand unterschiedlicher Fragestellungen und Beispiele zeigen wir auf, wie unterschiedliche Abfragen gestaltet werden können. Dabei nutzen wir die europäischen Datenplattform (https://data.europa.eu/de). Wie sooft führen viele Wege nach Rom und die Abfragen können je nach persönlichen Vorlieben des/der Benutzers/in variieren. Deswegen schlagen wir einige Alternativen vor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Teil widmen wir uns einer praktischen SPARQL-Übung, indem wir uns mit der folgenden Forschungsfrage auseinandersetzen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wie viele Datensätze in der Form von offenen Daten bietet jedes Bundesland an?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst widmen wir uns technischen Basis, mit der wir die SPARQL-Abfragen umsetzen werden. Wir arbeiten mit Jupyter Notebook - ein Dateiformat, das es ermöglicht, Erklärtext und Code in verschiedenen Programmiersprachen darzustellen. Somit wird die visuelle Darstellung von echtem Code für die Abfragen, deren Ergebnisse und die Erläuterungen der aufgerufenen Befehle samt anderer Kommentare ermöglicht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somit können wir uns der Analyse der SPARQL-Syntax widmen, indem wir uns die Abfragen für die Forschungsfragen ansehen. Als allererstes muss ein sogenannter \"endpoint\" definiert werden. Der endpoint ist die maschinelesbare Schnittstelle auf das Repositorium, in dem die Metadaten gespeichert sind, die wir abfragen wollen. Bei der Arbeit mit einem Online-SPARQL-Werkzeug ist die Definition eines endpoints oft nicht nötig, da der schon automatisch definiert ist. Im Portal GOVDATA ist der endpoint die Schnittstelle zum deutschen Open Data Portal [govdata.de](https://www.govdata.de/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für unsere Beispiele wollen wir das europäischen Datenportal durchsuchen. Den finden wir auf der folgenden Webseite - . Danach verwenden den wir folgende \"Magic\", d.h. einen Befehl, der Teil vom SPARQL-Python-Paket ist, der es uns erlaubt, alle künftigen Abfragen mit unserem endpoint zu verknüpfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"krn-spql\"><div class=\"magic\">Endpoint set to: https://data.europa.eu/sparql</div></div>"
      ],
      "text/plain": [
       "Endpoint set to: https://data.europa.eu/sparql\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%endpoint https://data.europa.eu/sparql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Mit dem festgelegten endpoint können wir SPARQL-Abfragen erstellen. Allerdings fragen wir nur die Metadaten ab, die zu den Datensätzen im Portal gespeichert sind. Siehe hierzu Kapitel ... . Bevor wir damit anfangen, möchten wir uns mit der Onthologie der gespeicherten Daten vertraut machen. Der zuvor erklärte Metatenstandard DCAT-AP ist zentral für die Erkundung von den Metadateneigentschaften und definiert die Struktur und den Inhalt der Metadatenfelder - https://www.dcat-ap.de/def/. \n",
    "Schauen wir uns nun die Struktur unserer ersten Abfrage an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX dcatde: <http://dcat-ap.de/def/dcatde/>\n",
    "PREFIX pg: <https://www.dcat-ap.de/def/politicalGeocoding/>\n",
    "\n",
    "SELECT ?uri ?title ?contributorid ?stateKey\n",
    "WHERE {\n",
    "    ?uri dct:title ?title .\n",
    "    ?uri dcatde:contributorID ?contributorid .\n",
    "  OPTIONAL {?uri pg:stateKey ?stateKey} .\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Erklärung des Codes\n",
    ":class: tip, dropdown\n",
    "\n",
    "Als erstes sehen wir die sogenannten PREFIXES. Die Prefixes sind ein nützliches Tool, das dabei helfen, auf die diversen Eigenschaften zu verweisen und auf eine abgekürzte Art und Weise die Bezüge zwischen diesen Eigenschaften zu schaffen. Sie sind wichtig für eine einfachere Gestaltung der Abfragen, aber nicht essenziell. Sie helfen lediglich, indem die ganzen Links nicht immer wieder ausgeschrieben werden müssen, und ermöglichen nur die Angabe von den Endungen nach den Prefixes. Alles wird klarer, wenn wir uns den WHERE-Abschnitt ansehen.\n",
    "\n",
    "Weiterhin gibt es den SELECT-Befehl. SELECT wählt die Properties bzw. die Eigenschaften, die aufgelistet werden sollen. Jede Eigenschaft entspricht einer Spalte, die in der Tabelle mit Ergebnissen zu sehen ist. Da im SELECT-Befehl die folgenden 3 Properties ausgeschrieben werden - ?uri ?title ?contributorid ?stateKey - bekommen wir die URIs, die Titel, die Namen der Datenbereitsteller und das Kürzel des jeweiligen Landes, aus dem der Datensatz stammt.\n",
    "\n",
    "Die genauen Benennungen der Properties (Labels) werden im DCAT-AP-Handbuch definiert, auf das wir zurückgreifen müssen, um die genauen Labels für jede Property zu finden.\n",
    "\n",
    "Was Ihnen noch auffallen könnte ist, dass die Spalte für das Bundesland (stateKey) leer ist. Leider liegt das daran, dass das Land nicht codiert worden ist. Somit bleiben diese Felder leer. Dies ist ein klares Beispiel für lückenhaftes Metadatenmanagement, das die Beantowrtung unserer Forschungsfrage erschwert. In der Praxis kommt es oft zu Fällen, in denen Abfragen nicht sehr erfolgreich sind, wegen unvollständigen Metadatenbeschreibungen. \n",
    "\n",
    "Als nächstes haben wir den Kern jeder SPARQL-Abfrage - den WHERE-Befehl. Der WHERE-Befehl definiert die Beobachtungen, die aufgelistet werden sollen, indem die Bedingungen definiert werden. Somit werden nur die Beobachtungen aufgelistet, die alle Bedungungen erfüllen. In der Abfrage ist auch OPTIONAL zu sehen - dies besagt, dass die folgende Bedingung nicht zwingend zu erfüllen ist. Das bedeutet, dass selbst die Beobachtungen, in unserem Fall die Datensätze, in der Liste stehen, die keine Ausprägung für die Eigentschaft stateKey (Verweis auf Land) haben. Da leider stateKey nicht mit codiert ist, können wir uns alle Datensätze ansehen, die auf die anderen Bedingungen treffen (URI, Titel und ID der Bereitsteller), ohne dass wir eine leere Liste bekommen. OPTIONAL ist ein gutes Werkzeug, das benutzt werden kann, wenn man sich nicht sicher ist, ob jeweiligen Properties ordentlich codiert sind.\n",
    "\n",
    "Was wahrscheinlich noch auffällt ist, dass in jeder Zeile in der WHERE-Funktion 3 Elemente zu sehen sind. Diese Struktur ist essentiell für die SPARQL-Sprache - durch die sogenannten \"triplets\" werden Bezüge zwischen den Eigenschaften erstellt. Jede Zeile bestimmt einen Bezug zwischen 2 Eigenschaften. Die erste Eigenschaft ist somit das Subjekt (S), das zweite Element - der Bezug, der aus einem Prefix und einer zusätzlichen Spezifizierung besteht, heißt das Prädikat (P), und das dritte - die zweite Eigenschaft, ist das Objekt (O). P entspricht einem Link, der darauf verweist, wo die zweite Eigentschaft zu finden ist. Die Einordnung der Eigenschaften ist nach dem W3C-Standard, der schon *in einem früheren Kapitel erklärt wurde*, definiert. In dem DCAT-AP-Handbuch ist dann die genaue Verortung von jeder Eingenschaft zu finden. Durch die Triplets fragen wir genau ab, welche Datensätze wir erfragen wollen, je nach den Bedingungen, die solche Datensätze erfüllen sollen. Mit unserer Abfrage suchen wir die Datensätze ab, die einen Titel, ein URI, einen mitcodierten Datenbereitsteller, und wenn vorhanden, einen Schlüssel für das Bundesland, haben, was leider bei keinem der Datensätze der Fall ist. Es lässt sich darauf schließen, dass diese Felder nicht verpflichtend ausgefüllt werden müssen. \n",
    "\n",
    "Wichtig zu bedenken ist, dass SPARQL leider keine Paginierungsfunktion unterstützt. Man muss es in der Regel auf Anwendungsebene handhaben, da SPARQL von sich aus nicht das Durchblättern von Ergebnissen wie eine Weboberfläche unterstützt. Stattdessen muss die Paginierung manuell durch die Verwendung von LIMIT und OFFSET in den Abfragen implementiert werden. Dies erfordert eine zusätzliche Logik in der Anwendung, um die aktuelle Seite Ausgabe vollständig zu sehen. \n",
    "\n",
    "Leider konnten wir unsere Fragestellung wegen mangelhafter Daten nicht ganz beantworten. Deshalb versuchen wir, unsere Fragestellung zu ändern und zusätzliche Beispiele von SPARQL-Abfragen damit aufzuzeigen.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPARQL",
   "language": "sparql",
   "name": "sparql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "sparql"
   },
   "mimetype": "application/sparql-query",
   "name": "sparql",
   "pygments_lexer": "sparql-nb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
